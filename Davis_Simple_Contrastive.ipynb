{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Davis_Simple_Contrastive.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1MUg4uXfXjbWkzPZkBD9ikVSyrXkUN37P",
      "authorship_tag": "ABX9TyOdz6bA40W+WYJODKbjcy8G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amaljayaranga/Solution/blob/master/Davis_Simple_Contrastive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orG80ct81EmH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "bd004445-fe2f-462f-ced6-0e833931a241"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import json\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import Image, display\n",
        "import torch\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "from argparse import ArgumentParser\n",
        "import copy\n",
        "\n",
        "parser = ArgumentParser(description='Solution Network')\n",
        "parser.add_argument('--batch_size', type=int, default=32)\n",
        "parser.add_argument('--constractive_loss_margin', type=float, default=0.8)\n",
        "parser.add_argument('--learning_rate', type=float, default=1e-3)\n",
        "parser.add_argument('--num_epochs', type=int, default=10)\n",
        "parser.add_argument('--weight_decay', type=float, default=1e-5)\n",
        "parser.add_argument('--mode', type=str, default='train')\n",
        "parser.add_argument('--device', type=str, default='cuda')\n",
        "parser.add_argument('--img_size', type=int, default=200)\n",
        "\n",
        "args, unknown = parser.parse_known_args()\n",
        "\n",
        "DEVICE = args.device\n",
        "if not torch.cuda.is_available():\n",
        "    DEVICE = 'cpu'\n",
        "\n",
        "\n",
        "class SimaseDavis(Dataset):\n",
        "\n",
        "  def __init__(self, json_data, memmap, need_classes):\n",
        "      self.memmap = memmap\n",
        "      self.json_data = json_data\n",
        "      self.need_classes = need_classes\n",
        "      self.having_classes = self.json_data[\"classes\"]\n",
        "      self.shape = self.json_data[\"shape\"]\n",
        "\n",
        "  def image_to_tensor(self,image, mean=0, std=1.):\n",
        "        image = image.astype(np.float32)\n",
        "        image = (image - mean) / std\n",
        "        image = image.transpose((2, 0, 1))\n",
        "        tensor = torch.from_numpy(image)\n",
        "        return tensor\n",
        "\n",
        "  def crop_objects(self, img_list):\n",
        "    objects = []\n",
        "    path = './drive/My Drive/Thesis_2020/dataset/'\n",
        "    for obj in img_list:\n",
        "        idx = (obj['index'])\n",
        "        x = obj['x']\n",
        "        y = obj['y']\n",
        "        width = obj['width']\n",
        "        height = obj['height']\n",
        "        img_path = path+str(idx)+'.jpg'\n",
        "        #display(Image(img_path))\n",
        "        image = cv2.imread(img_path)\n",
        "        crop_img = image[y:y + height, x:x + width]\n",
        "        #plt.imshow(crop_img, interpolation='nearest')\n",
        "        #plt.show()\n",
        "        img_resized = cv2.resize(crop_img, (args.img_size,args.img_size), interpolation = cv2.INTER_AREA)\n",
        "        objects.append(self.image_to_tensor(img_resized))\n",
        "    return objects\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    target = np.random.randint(0, 2)\n",
        "    crop_objects = []\n",
        "\n",
        "    if target == 0 :\n",
        "      class_label = np.random.choice(self.need_classes)\n",
        "      images_per_class = self.having_classes[class_label]\n",
        "      selection = np.random.choice(images_per_class, 2)\n",
        "      crop_objects = self.crop_objects(selection)\n",
        "     \n",
        "    else:\n",
        "       class_label = np.random.choice(self.need_classes)\n",
        "       images_per_class = self.having_classes[class_label]\n",
        "       img1  = np.random.choice(images_per_class)\n",
        "       temp_list = copy.deepcopy(self.need_classes)\n",
        "       temp_list.remove(class_label)\n",
        "       other_class = np.random.choice(temp_list)\n",
        "       images_other_class = self.having_classes[other_class]\n",
        "       img2  = np.random.choice(images_other_class)\n",
        "       crop_objects = self.crop_objects([img1,img2])\n",
        "    \n",
        "    return crop_objects[0], crop_objects[1], target\n",
        "\n",
        "  def __len__(self):\n",
        "      return self.shape[0]\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        #conv and fc works as encoder\n",
        "        self.conv = nn.Sequential(nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5),\n",
        "                                  nn.ReLU(),\n",
        "                                  nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                                  nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5),\n",
        "                                  nn.ReLU(),\n",
        "                                  nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                                  nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5),\n",
        "                                  nn.ReLU(),\n",
        "                                  nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "                                  )\n",
        "        \n",
        "        # output 128, 21, 21 \n",
        "        self.fc = nn.Sequential(nn.Linear(128 * 21 * 21, 1024),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Linear(1024, 1024),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Linear(1024, 256)\n",
        "                                )\n",
        "        \n",
        "    def forward(self, in1, in2):\n",
        "        x = torch.cat((in1, in2), dim=0)\n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.size()[0], -1)\n",
        "        x = self.fc(x)\n",
        "        z_out1, Z_out2 = torch.split(x, x.size(0) // 2, dim=0)\n",
        "        return z_out1, Z_out2\n",
        "\n",
        "\n",
        "class ContrastiveLoss(nn.Module):\n",
        "\n",
        "    def __init__(self, margin):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output, target):\n",
        "        eq_distance = F.pairwise_distance(output[0], output[1])\n",
        "        loss = 0.5 * (1 - target) * torch.pow(eq_distance, 2) + \\\n",
        "               0.5 * target * torch.pow(torch.clamp(self.margin - eq_distance, min=0.00), 2)\n",
        "        return loss.mean()\n",
        "        \n",
        "\n",
        "\n",
        "folder_path = './drive/My Drive/Thesis_2020/'\n",
        "with open(folder_path+'davis-json.txt') as json_file:\n",
        "    davis_json = json.load(json_file)\n",
        "\n",
        "memmap_path = './drive/My Drive/Thesis_2020/memmap/'\n",
        "shape = davis_json[\"shape\"]\n",
        "complete_memmap = memmap_path+'davis.mmap'\n",
        "davis_memmap = np.memmap(complete_memmap, dtype='uint8', mode='r', shape=tuple(shape))\n",
        "\n",
        "\n",
        "need_classes = ['person', 'tennis racket','sports ball','horse','surfboard','skateboard',\n",
        "                'sheep','motorcycle','backpack','kite','sports ball','bird','dog','bicycle',\n",
        "                'handbag']\n",
        "\n",
        "davis_dataset = SimaseDavis(davis_json,davis_memmap,need_classes)\n",
        "davis_dataloader = torch.utils.data.DataLoader(davis_dataset, batch_size = args.batch_size, shuffle=True)\n",
        "\n",
        "encoder = Encoder()\n",
        "encoder = encoder.to(DEVICE)\n",
        "\n",
        "criterion = ContrastiveLoss(margin=args.constractive_loss_margin)\n",
        "optimizer = torch.optim.Adam(params=encoder.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)\n",
        "\n",
        "print('training started')\n",
        "\n",
        "encoder.train()\n",
        "torch.set_grad_enabled(True)\n",
        "\n",
        "for epoch in range(args.num_epochs):\n",
        "\n",
        "  batch_losses = []\n",
        "\n",
        "  for batch in davis_dataloader:\n",
        "      img_objects_1, img_objects_2, target  = batch\n",
        "      img_objects_1 = img_objects_1.to(DEVICE)\n",
        "      img_objects_2 = img_objects_2.to(DEVICE)\n",
        "\n",
        "      z_out1, z_out2 = encoder(img_objects_1, img_objects_2)\n",
        "\n",
        "      z_out = [z_out1, z_out2]\n",
        "\n",
        "      target = target.to(DEVICE)\n",
        "\n",
        "      loss = criterion(z_out, target)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      batch_losses.append(loss.item())\n",
        "  \n",
        "  print('Epoch : ', epoch+1, 'loss : ', np.mean(batch_losses))\n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training started\n",
            "Epoch :  1 loss :  6.376217713113874\n",
            "Epoch :  2 loss :  0.08317986456677318\n",
            "Epoch :  3 loss :  0.09014493541326374\n",
            "Epoch :  4 loss :  0.0715072265593335\n",
            "Epoch :  5 loss :  0.07269156526308507\n",
            "Epoch :  6 loss :  0.06413766578771174\n",
            "Epoch :  7 loss :  0.05644102836959064\n",
            "Epoch :  8 loss :  0.050493661779910326\n",
            "Epoch :  9 loss :  0.0497823950718157\n",
            "Epoch :  10 loss :  0.04216685553546995\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}