{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Context_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1h_XhQYJx35FJuICmdsnq080hmCRip0wO",
      "authorship_tag": "ABX9TyOPAo5nxdj0TuKXqCPvkca7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MLenthusiastic/Solution/blob/master/Context_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZYE5dd07IFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import json\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns;sns.set()\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import Image, display\n",
        "import torch\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "from argparse import ArgumentParser\n",
        "import copy\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import tensorflow as tf\n",
        "import tensorboard as tb\n",
        "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n",
        "\n",
        "\n",
        "parser = ArgumentParser(description='Solution Network')\n",
        "parser.add_argument('--batch_size', type=int, default=16)\n",
        "parser.add_argument('--constractive_loss_margin', type=float, default=0.8)\n",
        "parser.add_argument('--learning_rate', type=float, default=1e-4)\n",
        "parser.add_argument('--num_epochs', type=int, default=20)\n",
        "parser.add_argument('--weight_decay', type=float, default=1e-5)\n",
        "parser.add_argument('--mode', type=str, default='train')\n",
        "parser.add_argument('--device', type=str, default='cuda')\n",
        "parser.add_argument('--img_size', type=int, default=200)\n",
        "parser.add_argument('--no_of_samples_per_class', type=int, default=100)\n",
        "parser.add_argument('--no_of_classes', type=int, default=50)\n",
        "parser.add_argument('--projector_img_size', type=int, default=32)\n",
        "\n",
        "args, unknown = parser.parse_known_args()\n",
        "\n",
        "DEVICE = args.device\n",
        "if not torch.cuda.is_available():\n",
        "    DEVICE = 'cpu'\n",
        "\n",
        "#previous trained encoder model\n",
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        #conv and fc works as encoder\n",
        "        self.conv = nn.Sequential(nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5),\n",
        "                                  nn.ReLU(),\n",
        "                                  nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                                  nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5),\n",
        "                                  nn.ReLU(),\n",
        "                                  nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                                  nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5),\n",
        "                                  nn.ReLU(),\n",
        "                                  nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "                                  )\n",
        "        \n",
        "        # output 128, 21, 21 \n",
        "        self.fc = nn.Sequential(nn.Linear(128 * 21 * 21, 1024),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Linear(1024, 1024),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Linear(1024, 128)\n",
        "                                )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.size()[0], -1)\n",
        "        z = self.fc(x)\n",
        "        return z\n",
        "\n",
        "class ContextDavis(Dataset):\n",
        "\n",
        "  def __init__(self, json_data, memmap):\n",
        "      self.memmap = memmap\n",
        "      self.json_data = json_data\n",
        "      self.shape = self.json_data[\"shape\"]\n",
        "      self.objects = self.json_data[\"objects\"]\n",
        "      self.contexts = self.json_data[\"contexts\"]\n",
        "      self.keys_of_images = list(self.contexts.keys())\n",
        "      self.keys_of_images.sort()\n",
        "      self.start_img_index = int(self.keys_of_images[0])\n",
        "      self.length = len(self.keys_of_images)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    correct_index = self.start_img_index + index\n",
        "    contexts_per_image = self.contexts[str(correct_index)]\n",
        "    \n",
        "    img_objects = []\n",
        "    img_classes = []\n",
        "    for context_image in contexts_per_image:\n",
        "      img_object = self.objects[str(context_image)]\n",
        "      img_object_width = img_object['width']\n",
        "      img_object_height = img_object['height']\n",
        "      image_ =  self.memmap[context_image, :, :img_object_width, :img_object_height].astype(np.float32)\n",
        "      class_ = img_object['class']\n",
        "\n",
        "      image_tensor_ext = torch.from_numpy(image_).unsqueeze(dim=0)\n",
        "      image_tensor = F.interpolate(image_tensor_ext, size=(args.img_size,args.img_size))\n",
        "      image_tensor = image_tensor.squeeze(dim=1)\n",
        "\n",
        "      img_objects.append(image_tensor)\n",
        "      img_classes.append(class_)\n",
        "\n",
        "    return [img_objects, img_classes]\n",
        "\n",
        "  def __len__(self):\n",
        "      return self.length\n",
        "\n",
        "\n",
        "folder_path = './drive/My Drive/'\n",
        "with open(folder_path+'test_davis_json.txt') as json_file:\n",
        "    davis_json = json.load(json_file)\n",
        "\n",
        "shape = davis_json[\"shape\"]\n",
        "memmap_path = folder_path+'test_davis.mmap'\n",
        "davis_memmap = np.memmap(memmap_path, dtype='uint8', mode='r', shape=tuple(shape))\n",
        "\n",
        "davis_dataset = ContextDavis(davis_json,davis_memmap)\n",
        "davis_dataloader = torch.utils.data.DataLoader(davis_dataset, batch_size=1, shuffle=False)\n",
        "#shuflling changes order and keep batch size 1\n",
        "\n",
        "#load previously trained encoder model\n",
        "model_path = './drive/My Drive/encoder_2.pth'\n",
        "encoder_model = Encoder()\n",
        "encoder_model.load_state_dict(torch.load(model_path))\n",
        "encoder_model.eval()\n",
        "\n",
        "for epoch in range(1,args.num_epochs+1):\n",
        "\n",
        "  for batch in davis_dataloader:\n",
        "\n",
        "      img_objects, classes = batch[0] , batch[1]\n",
        "      z_vectors = []\n",
        "      for img_object in img_objects:\n",
        "          z_vectors.append(encoder_model(img_object.squeeze(dim=1)))\n",
        "\n",
        "      \n",
        "\n",
        "\n",
        "      \n",
        "      #break\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "data = davis_dataset.__getitem__(0)\n",
        "imgs, clss  = data\n",
        "for i in imgs:\n",
        "  j = i[0].numpy().transpose(2,1,0)\n",
        "  cv2_imshow(j)\n",
        "'''\n",
        "'''\n",
        "batch = next(iter(davis_dataloader))\n",
        "\n",
        "print(len(batch))\n",
        "print(batch[0][0]) # for images\n",
        "print(batch[1][0]) #for classes\n",
        "\n",
        "imges = batch[0][0]\n",
        "for i in imges:\n",
        "  j = i[0].numpy().transpose(2,1,0)\n",
        "  cv2_imshow(j)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}